{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc, copy\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from scipy.signal import welch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('dataset.npz')\n",
    "\n",
    "xtrs_r = data['train_s']\n",
    "xtrns_r = data['train_ns']\n",
    "xtes_r = data['test_s']\n",
    "xtens_r = data['test_ns']\n",
    "\n",
    "# non seizure is 0，seizure is 1\n",
    "ytrs = np.zeros((xtrs_r.shape[0],1))\n",
    "ytrns = np.zeros((xtrns_r.shape[0],1))\n",
    "ytes = np.zeros((xtes_r.shape[0],1))\n",
    "ytens = np.zeros((xtens_r.shape[0],1))\n",
    "\n",
    "ytrs = ytrs + 1\n",
    "ytrns = ytrns\n",
    "ytes = ytes + 1\n",
    "ytens = ytens\n",
    "\n",
    "x_train = np.concatenate([xtrs_r,xtrns_r])\n",
    "y_train = np.concatenate([ytrs,ytrns])\n",
    "x_test = np.concatenate([xtes_r,xtens_r])\n",
    "y_test = np.concatenate([ytes,ytens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train_sta = x_train\n",
    "x_test_sta = x_test\n",
    "\n",
    "x_train_sta = np.asfarray(x_train_sta)\n",
    "x_test_sta = np.asfarray(x_test_sta)\n",
    "\n",
    "x_tloader = torch.tensor(x_train_sta,dtype=torch.float32).view(-1,256,1)\n",
    "y_tloader = torch.tensor(y_train, dtype=torch.long).view(y_train.shape[0])\n",
    "\n",
    "# 将标签转换为 PyTorch 张量\n",
    "y_train_tensor = torch.tensor(y_tloader)\n",
    "# 计算每个类别的数量\n",
    "class_counts = torch.bincount(y_train_tensor)\n",
    "# 计算类别权重\n",
    "class_weights = 1.0 / class_counts.float()\n",
    "print(class_weights)\n",
    "\n",
    "\n",
    "print(x_tloader.shape, y_tloader.shape)\n",
    "\n",
    "x_vloader = torch.tensor(x_test_sta, dtype=torch.float32).view(-1,256,1)\n",
    "y_vloader = torch.tensor(y_test, dtype=torch.long).view(y_test.shape[0])\n",
    "\n",
    "print(x_vloader.shape, y_vloader.shape)\n",
    "\n",
    "train_dataset = TensorDataset(x_tloader, y_tloader)\n",
    "test_dataset = TensorDataset(x_vloader, y_vloader)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=128,shuffle=True,num_workers=4)\n",
    "# test_loader = DataLoader(test_dataset,batch_size=len(test_dataset),shuffle=False,num_workers=4)\n",
    "test_loader = DataLoader(test_dataset,batch_size=128,shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义RNN架构\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=1,  # 每个序列点的特征维度，例如使用5个频段，则等于5\n",
    "            hidden_size=64,  # 隐藏层参数\n",
    "            num_layers=1,  # RNN layers\n",
    "            batch_first=True,  # input & output 会是以 batch size 为第一维度的特征集 e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.flag = 1\n",
    "        self.out = nn.Linear(64, 2)  # 输出层\n",
    "\n",
    "    def forward(self, x):\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)  # None 表示 hidden state 会用全0的 state\n",
    "        # out = self.out(r_out[:, -1, :])\n",
    "        out = self.out(h_n[0])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train(model, train_loader, test_loader, criterion, optimizer):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    total_samples = 0\n",
    "    for data, target in train_loader:\n",
    "        data,target = data.cuda(),target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total_samples += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        TP += ((predicted == 1) & (target == 1)).sum().item()\n",
    "        FN += ((predicted == 0) & (target == 1)).sum().item()\n",
    "        TN += ((predicted == 0) & (target == 0)).sum().item()\n",
    "        FP += ((predicted == 1) & (target == 0)).sum().item()\n",
    "\n",
    "    acc = correct / total_samples\n",
    "    sen = TP / (TP + FN)\n",
    "    spe = TN / (TN + FP)\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Train Epoch {epoch+1}/{num_epochs}, Acc: {acc:.4f}, Sen: {sen:.4f}, Spe: {spe:.4f}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    # 测试阶段\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    total_samples = 0\n",
    "    last_metric = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data,target = data.cuda(),target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total_samples += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        TP += ((predicted == 1) & (target == 1)).sum().item()\n",
    "        FN += ((predicted == 0) & (target == 1)).sum().item()\n",
    "        TN += ((predicted == 0) & (target == 0)).sum().item()\n",
    "        FP += ((predicted == 1) & (target == 0)).sum().item()\n",
    "\n",
    "    acc = correct / total_samples\n",
    "    sen = TP / (TP + FN)\n",
    "    spe = TN / (TN + FP)\n",
    "    score = sen*spe\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    print(f\"Test Epoch {epoch+1}/{num_epochs}, Acc: {acc:.4f}, Sen: {sen:.4f}, Spe: {spe:.4f}, Loss: {loss:.4f}\")\n",
    "    return model, score, sen, spe, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " # 设置训练参数\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# 创建模型实例\n",
    "lenet = RNN()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(lenet.parameters(), lr=learning_rate)\n",
    "\n",
    "lenet.to(device)\n",
    "\n",
    "best_model = None\n",
    "b_score = 0\n",
    "b_acc = 0\n",
    "b_sen = 0\n",
    "b_spe = 0\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    trained_model, score, sen, spe, acc = train(lenet, train_loader, test_loader, criterion, optimizer)\n",
    "    if score > b_score:\n",
    "        best_model = copy.deepcopy(trained_model)\n",
    "        b_score = score\n",
    "        b_acc = acc\n",
    "        b_sen = sen\n",
    "        b_spe = spe\n",
    "print(f\"Final metrics , Score: {b_score:.4f}, Acc: {b_acc:.4f}, Sen: {b_sen:.4f}, Spe: {b_spe:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "# 保存model为onnx格式\n",
    "# Prepare input tensor\n",
    "input_tensor = torch.randn(1, 256, 1)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Move model to the device\n",
    "best_model.to(device)\n",
    "\n",
    "directory = 'rnn'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "# Export models as ONNX files\n",
    "torch.onnx.export(best_model, input_tensor, \"rnn/lstm.onnx\", opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = best_model(x_vloader.to(device))\n",
    "    ypred = torch.argmax(outputs.cpu(), dim=1)\n",
    "    TP = ((ypred == 1) & (y_vloader == 1)).sum()\n",
    "    FN = ((ypred == 0) & (y_vloader == 1)).sum()\n",
    "    TN = ((ypred == 0) & (y_vloader == 0)).sum()\n",
    "    FP = ((ypred == 1) & (y_vloader == 0)).sum()\n",
    "    sen = TP / (TP + FN)\n",
    "    spe = TN / (TN + FP)\n",
    "    print(sen,spe)\n",
    "    print(TP,FN,TN,FP)\n",
    "    print(ypred.sum(),y_test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate model\n",
    "from sklearn.metrics import classification_report,accuracy_score,roc_curve\n",
    "from sklearn.metrics import confusion_matrix,auc,RocCurveDisplay,plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "target_names = ['non-seizure', 'seizure']\n",
    "print(classification_report(y_vloader, ypred, target_names=target_names))\n",
    "confusion = confusion_matrix(y_vloader,ypred)\n",
    "ax = sns.heatmap(confusion, annot=True, fmt='g', cmap='Blues')\n",
    "ax.set_title('Confusion Matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['non-seizure', 'seizure'])\n",
    "ax.yaxis.set_ticklabels(['non-seizure', 'seizure'])\n",
    "\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "Acc=(TP+TN)/float(TP+TN+FP+FN)\n",
    "Sen=TP / float(TP+FN)\n",
    "Spe=TN / float(TN+FP)\n",
    "print('acc', Acc, 'sen',Sen,'spe',Spe)\n",
    "plt.savefig('rnn/matrix.png', dpi=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "dl_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
