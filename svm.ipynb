{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMINT MODEL TRAINING\n",
    "# Author： YanLi@Fudan university\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import re\n",
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from scipy.signal import welch,sosfiltfilt,detrend,butter\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,accuracy_score,roc_curve\n",
    "from sklearn.metrics import confusion_matrix,auc,RocCurveDisplay,plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import class_weight\n",
    "import math\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "# 忽略DataConversionWarning警告\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集的numpy环境\n",
    "# train_s\n",
    "# train_ns\n",
    "# test_s\n",
    "# test_ns\n",
    "data = np.load('dataset.npz')\n",
    "\n",
    "# 训练集及label生成\n",
    "xtrs_r = data['train_s']\n",
    "xtrns_r = data['train_ns']\n",
    "ytrs = np.zeros((xtrs_r.shape[0],1))\n",
    "ytrns = np.zeros((xtrns_r.shape[0],1))\n",
    "# seizure is 1, non seizure is 0\n",
    "ytrs = ytrs + 1\n",
    "ytrns = ytrns\n",
    "\n",
    "# 测试集及label生成\n",
    "xtes_r = data['test_s']\n",
    "xtens_r = data['test_ns']\n",
    "ytes = np.zeros((xtes_r.shape[0],1))\n",
    "ytens = np.zeros((xtens_r.shape[0],1))\n",
    "# seizure is 1, non seizure is 0\n",
    "ytes = ytes + 1\n",
    "ytens = ytens\n",
    "\n",
    "# 构建完整的训练集和测试集\n",
    "X_train = np.concatenate([xtrs_r,xtrns_r])\n",
    "y_train = np.concatenate([ytrs,ytrns])\n",
    "\n",
    "X_test = np.concatenate([xtes_r,xtens_r])\n",
    "y_test = np.concatenate([ytes,ytens])\n",
    "\n",
    "print(y_train.shape, y_test.shape)\n",
    "plt.plot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征提取，四个时域特征，方差，能量，非线性能量，香农熵\n",
    "def shannon_entropy(X):\n",
    "    n = len(X)\n",
    "    # 使用Sturges规则计算直方图的bins数\n",
    "    k = int(math.ceil(1 + math.log2(n)))\n",
    "    # 计算每个bin中数据的数量\n",
    "    hist, _ = np.histogram(X, bins=k)\n",
    "    # 计算每个bin中数据的概率\n",
    "    probs = hist / float(n)\n",
    "    # 计算香农熵\n",
    "    entropy = -np.sum([p * np.log2(p) for p in probs if p != 0])\n",
    "    return entropy\n",
    "\n",
    "def feature_extraction(X_A, X_B):\n",
    "    # Calculate time-domain features for X_A\n",
    "    var_A = np.var(X_A, axis=1)\n",
    "    energy_A = np.sum(np.square(X_A), axis=1)\n",
    "    nonlinear_energy_A = np.sum(X_A[:, 1:-1]**2 - X_A[:, :-2]*X_A[:, 2:], axis=1)\n",
    "    entropy_A = np.apply_along_axis(shannon_entropy, axis=1, arr=X_A)\n",
    "    X_train_features = np.column_stack((var_A, energy_A, nonlinear_energy_A, entropy_A))\n",
    "\n",
    "    # Calculate time-domain features for X_B\n",
    "    var_B = np.var(X_B, axis=1)\n",
    "    energy_B = np.sum(np.square(X_B), axis=1)\n",
    "    nonlinear_energy_B = np.sum(X_B[:, 1:-1]**2 - X_B[:, :-2]*X_B[:, 2:], axis=1)\n",
    "    entropy_B = np.apply_along_axis(shannon_entropy, axis=1, arr=X_B)\n",
    "    X_test_features = np.column_stack((var_B, energy_B, nonlinear_energy_B, entropy_B))\n",
    "\n",
    "    return X_train_features, X_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features , X_test_features = feature_extraction(X_train , X_test)\n",
    "print(X_train_features.shape,X_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training the SVM model\n",
    "# X_trainf , X_testf\n",
    "target_names = ['non-seizure', 'seizure']\n",
    "svm = SVC(class_weight='balanced') # can change different kernel kernel='linear'\n",
    "svm.fit(X_train_features , y_train)\n",
    "ypred = svm.predict(X_test_features)\n",
    "\n",
    "# plt.plot(ypred, label='ypred')\n",
    "plt.plot(ypred, 'o', color='black', label='ypred');\n",
    "plt.plot(y_test, label='ytest')\n",
    "plt.legend()\n",
    "y_score=svm.decision_function(X_test_features)\n",
    "\n",
    "print(\"accuracy is:\", 100*accuracy_score(y_test , ypred))\n",
    "print (classification_report(y_test, ypred, target_names=target_names))\n",
    "fpr, tpr, thresholds = roc_curve(y_test , y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,estimator_name='svm')\n",
    "display.plot()\n",
    "\n",
    "\n",
    "confusion = confusion_matrix(y_test,ypred)\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "Accuracy=(TP+TN)/float(TP+TN+FP+FN)\n",
    "Sensitivity=TP / float(TP+FN)\n",
    "Specificity=TN / float(TN+FP)\n",
    "print('acc', Accuracy, 'sensitivity',Sensitivity,'specificity',Specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.heatmap(confusion, annot=True, fmt='g', cmap='Blues')\n",
    "sns.set(font_scale=1)\n",
    "ax.set_title('Confusion Matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['non-seizure', 'seizure'])\n",
    "ax.yaxis.set_ticklabels(['non-seizure', 'seizure'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('matrix.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存SVM模型\n",
    "from joblib import dump, load\n",
    "directory = 'svm'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "dump(svm, 'svm/svm.joblib') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "dl_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
