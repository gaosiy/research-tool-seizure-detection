{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMINT DEAL WITH CHB-MIT DATASET\n",
    "# Author： YanLi@Fudan university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import re\n",
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "# 忽略RuntimeWarning警告\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"Channel names are not unique\")\n",
    "np.random.seed(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = 0\n",
    "ch_list = [20, 3, 19, 10, 15, 13, 4, 16, 6, 1]\n",
    "patient_list = ['chb01','chb02','chb03','chb04','chb05','chb06','chb07','chb08','chb09','chb10']\n",
    "dataset_dir = 'C:/Users/gaosiy/Desktop/chb_data/'\n",
    "ch = ch_list[current]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查并确认通道是否正确\n",
    "raw = mne.io.read_raw_edf(dataset_dir+patient_list[current]+'/'+patient_list[current]+'_02.edf', verbose=False)\n",
    "# 获取通道名字列表\n",
    "ch_names = raw.ch_names\n",
    "# 打印通道名字列表 \n",
    "print('Channel is',ch_names[ch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_info(info_path):\n",
    "\n",
    "    with open(info_path, 'r') as infile:\n",
    "        info_string = infile.read()\n",
    "    \n",
    "    s_name = []\n",
    "    n_name = []\n",
    "    tmlist = []\n",
    "    seizure_info = []\n",
    "    non_seizure_info = []\n",
    "    start_sec = []\n",
    "    stop_sec = []\n",
    "    info_array = info_string.split('\\n\\n')\n",
    "\n",
    "    for block in info_array:\n",
    "        tmlist = block.split('\\n')\n",
    "        if 'File Name:' in block:\n",
    "            if  'Seizure ' in block:\n",
    "                s_name = tmlist[0][tmlist[0].index('chb'):]\n",
    "                for i in range(3, len(tmlist)):\n",
    "                    \n",
    "                    if 'Start' in tmlist[i]:\n",
    "                        start_sec.append(int(re.search(r\"Start Time: ([0-9]*) seconds\", tmlist[i]).group(1)))\n",
    "                    if 'End' in tmlist[i]:\n",
    "                        stop_sec.append(int(re.search(r\"End Time: ([0-9]*) seconds\", tmlist[i]).group(1)))\n",
    "                \n",
    "                seizure_info.append([s_name, start_sec, stop_sec])\n",
    "                start_sec = []\n",
    "                stop_sec = []\n",
    "            else:\n",
    "                non_seizure_info.append(tmlist[0][tmlist[0].index('chb'):])\n",
    "                \n",
    "    return seizure_info, non_seizure_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seizure_info, non_seizure_info = load_info(dataset_dir+patient_list[current]+'-summary.txt')\n",
    "print('patients',patient_list[current])\n",
    "print('seizure files\\n',seizure_info)\n",
    "print('nonseizure files\\n',non_seizure_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得不包含癫痫发作的数据\n",
    "def get_noseizure_file_data(name):    \n",
    "    edf_filename = dataset_dir + patient_list[current]+ \"/\" + name\n",
    "    edf = mne.io.read_raw_edf(edf_filename,stim_channel=None, verbose=False)\n",
    "    data = edf.get_data()[ch].astype(np.float32)* 1e6 #  to uV\n",
    "    data = np.array(data)\n",
    "    data_1s = data.reshape(-1, 256)\n",
    "    return data_1s\n",
    "\n",
    "ns_data = np.empty([0, 256], dtype=np.float32)\n",
    "for name in non_seizure_info:\n",
    "    tem = get_noseizure_file_data(name)\n",
    "    ns_data = np.concatenate([ns_data, tem], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 癫痫发作数据获取\n",
    "def get_seizure_file_data(name):  \n",
    "    print(name)\n",
    "    info = name[0]\n",
    "    start = name[1][0]\n",
    "    stop = name[2][0]\n",
    "    edf_filename = dataset_dir + patient_list[current]+ \"/\" + info\n",
    "    edf = mne.io.read_raw_edf(edf_filename,stim_channel=None, verbose=False)\n",
    "    data = edf.get_data()[ch].astype(np.float32)* 1e6 #  to uV\n",
    "    data = np.array(data)\n",
    "    data_1s = data.reshape(-1, 256)\n",
    "    # 选取癫痫部分数据\n",
    "    seizure_len = stop - start\n",
    "    head_tail_len = round(seizure_len/2)\n",
    "    s_data = data_1s[start-1:stop-1]\n",
    "    # 拼接前后的非发作部分\n",
    "    ns_head_data = data_1s[:start-1]\n",
    "    ns_tail_data = data_1s[stop-1:]\n",
    "\n",
    "    ns_data = np.concatenate([ns_head_data,ns_tail_data])\n",
    "    return s_data, ns_data\n",
    "\n",
    "s_data = np.empty([0, 256], dtype=np.float32)\n",
    "ns_data_add = np.empty([0, 256], dtype=np.float32)\n",
    "for info in seizure_info:\n",
    "    s, ns = get_seizure_file_data(info)\n",
    "    s_data = np.concatenate([s_data, s], axis=0) \n",
    "    ns_data_add = np.concatenate([ns_data_add, ns], axis=0) \n",
    "print('seizure ', s_data.shape[0], '\\nnoseizure ', ns_data_add.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两部分非发作的拼接起来，生成最终的非发作集\n",
    "ns = np.concatenate([ns_data, ns_data_add], axis=0)\n",
    "s = s_data\n",
    "print('ns：',ns.shape[0], 's:',s.shape[0])\n",
    "\n",
    "# 去掉重复数据\n",
    "ns_de = np.unique(ns, axis=0)\n",
    "s_de = np.unique(s, axis=0)\n",
    "\n",
    "print('ns：',ns_de.shape[0], 's:',s_de.shape[0])\n",
    "\n",
    "# 去掉异常数据，1s中所有数据相同\n",
    "def check_duplicate_arrays(arr):\n",
    "    index_list = []\n",
    "    for i, sub_arr in enumerate(arr):\n",
    "        if all(x == sub_arr[0] for x in sub_arr):\n",
    "            index_list.append(i)\n",
    "    if len(index_list)>0:\n",
    "        print('Warning!delte bad data ',index_list)\n",
    "        arr = np.delete(arr, index_list, axis=0)\n",
    "    else:\n",
    "        print('pass!')\n",
    "    return arr\n",
    "ns_de = check_duplicate_arrays(ns_de)\n",
    "s_de = check_duplicate_arrays(s_de)\n",
    "\n",
    "\n",
    "# 非发作训练集测试集划分\n",
    "N = ns_de.shape[0]   \n",
    "np.random.shuffle(ns_de)\n",
    "cut_point = int(N*0.7)\n",
    "train_ns = ns_de[:cut_point]\n",
    "test_ns = ns_de[cut_point:]\n",
    "\n",
    "# 发作训练集测试集划分\n",
    "N = s_de.shape[0]   \n",
    "np.random.shuffle(s_de)\n",
    "cut_point = int(N*0.7)\n",
    "train_s = s_de[:cut_point]\n",
    "test_s = s_de[cut_point:]\n",
    "\n",
    "print('训练集正样本',train_s.shape[0])\n",
    "print('训练集负样本',train_ns.shape[0])\n",
    "print('测试集正样本',test_s.shape[0])\n",
    "print('测试集负样本',test_ns.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集测试集保存为文件，供不同算法测试使用\n",
    "# train_s\n",
    "# train_ns\n",
    "# test_s\n",
    "# test_ns\n",
    "\n",
    "print(\"train_s：\", train_s.nbytes/1024/1024, \"Mb\")\n",
    "print(\"train_ns：\", train_ns.nbytes/1024/1024, \"Mb\")\n",
    "print(\"test_s：\", test_s.nbytes/1024/1024, \"Mb\")\n",
    "print(\"test_ns：\", test_ns.nbytes/1024/1024, \"Mb\")\n",
    "\n",
    "np.savez('dataset.npz', \n",
    "         train_s=train_s, \n",
    "         train_ns=train_ns, \n",
    "         test_s=test_s,\n",
    "         test_ns=test_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "dl_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
