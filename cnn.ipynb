{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMINT MODEL TRAINING\n",
    "# Author： YanLi@Fudan university\n",
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch, gc\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "from scipy import signal\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('dataset.npz')\n",
    "\n",
    "xtrs_r = data['train_s']\n",
    "xtrns_r = data['train_ns']\n",
    "xtes_r = data['test_s']\n",
    "xtens_r = data['test_ns']\n",
    "\n",
    "fs = 256\n",
    "nseg = 128\n",
    "overlap = 116\n",
    "\n",
    "upsize = 2\n",
    "imagesize = 22 * upsize\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# train set\n",
    "for i in tqdm(range(xtrs_r.shape[0])):\n",
    "    f, t, Zxx = signal.stft(xtrs_r[i], fs, nperseg=nseg, noverlap=overlap, padded=False)\n",
    "    data = np.abs(Zxx[(1< f)&(f<46)])\n",
    "    data = data.repeat(upsize, axis = 0).repeat(upsize, axis = 1)\n",
    "    data = data.reshape((1,imagesize,imagesize)).astype('float32')\n",
    "    x_train.append(data)\n",
    "    y_train.append(int(1))\n",
    "#     data = torch.tensor(data)\n",
    "\n",
    "for i in tqdm(range(xtrns_r.shape[0])):\n",
    "    f, t, Zxx = signal.stft(xtrns_r[i], fs, nperseg=nseg, noverlap=overlap, padded=False)\n",
    "    data = np.abs(Zxx[(1< f)&(f<46)])\n",
    "    data = data.repeat(upsize, axis = 0).repeat(upsize, axis = 1)\n",
    "    data = data.reshape((1,imagesize,imagesize)).astype('float32')\n",
    "#     data = torch.tensor(data)    \n",
    "    x_train.append(data)\n",
    "    y_train.append(int(0))\n",
    "\n",
    "# test set\n",
    "for i in tqdm(range(xtes_r.shape[0])):\n",
    "    f, t, Zxx = signal.stft(xtes_r[i], fs, nperseg=nseg, noverlap=overlap, padded=False)\n",
    "    data = np.abs(Zxx[(1< f)&(f<46)])\n",
    "    data = data.repeat(upsize, axis = 0).repeat(upsize, axis = 1)\n",
    "    data = data.reshape((1,imagesize,imagesize)).astype('float32')\n",
    "#     data = torch.tensor(data)\n",
    "    x_test.append(data)\n",
    "    y_test.append(int(1))\n",
    "\n",
    "for i in tqdm(range(xtens_r.shape[0])):\n",
    "    f, t, Zxx = signal.stft(xtens_r[i], fs, nperseg=nseg, noverlap=overlap, padded=False)\n",
    "    data = np.abs(Zxx[(1< f)&(f<46)])\n",
    "    data = data.repeat(upsize, axis = 0).repeat(upsize, axis = 1)\n",
    "    data = data.reshape((1,imagesize,imagesize)).astype('float32')\n",
    "    x_test.append(data)\n",
    "    y_test.append(int(0))\n",
    "#     data = torch.tensor(data)\n",
    "\n",
    "\n",
    "x_train = torch.Tensor(np.array(x_train))\n",
    "y_train = torch.Tensor(np.array(y_train)).long()\n",
    "x_test = torch.Tensor(np.array(x_test))\n",
    "y_test = torch.Tensor(np.array(y_test)).long()\n",
    "\n",
    "\n",
    "# 将标签转换为 PyTorch 张量\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "# 计算每个类别的数量\n",
    "class_counts = torch.bincount(y_train_tensor)\n",
    "# 计算类别权重\n",
    "class_weights = 1.0 / class_counts.float()\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据打包成dataset\n",
    "my_dataset = TensorDataset(x_train,y_train) # create your datset\n",
    "train_dataloader= DataLoader(dataset=my_dataset, num_workers=4, pin_memory=False, batch_size=256, shuffle=True)\n",
    "\n",
    "my_dataset = TensorDataset(x_test,y_test) # create your datset\n",
    "# test_dataloader = DataLoader(dataset=my_dataset, num_workers=4, pin_memory=False, batch_size=len(my_dataset))\n",
    "test_dataloader = DataLoader(dataset=my_dataset, num_workers=4, pin_memory=False, batch_size=256)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "dataloaders = {'train': train_dataloader, 'val': test_dataloader}\n",
    "\n",
    "a = len(train_dataloader.dataset)\n",
    "b = len(test_dataloader.dataset)\n",
    "dataset_sizes = {'train': a, 'val': b}\n",
    "\n",
    "t_loss = []\n",
    "v_loss = []\n",
    "t_acc = []\n",
    "v_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LeNet-5网络结构\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        # 定义模型\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=6,kernel_size=(5,5),stride=1,padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(in_channels=6,out_channels=16,kernel_size=(5,5),stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=1296, out_features=120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=120, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=2)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        # 定义前向算法\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        result = self.classifier(x)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train(model, train_loader, test_loader, criterion, optimizer):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    total_samples = 0\n",
    "    for data, target in train_loader:\n",
    "        data,target = data.cuda(),target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total_samples += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        TP += ((predicted == 1) & (target == 1)).sum().item()\n",
    "        FN += ((predicted == 0) & (target == 1)).sum().item()\n",
    "        TN += ((predicted == 0) & (target == 0)).sum().item()\n",
    "        FP += ((predicted == 1) & (target == 0)).sum().item()\n",
    "\n",
    "    acc = correct / total_samples\n",
    "    sen = TP / (TP + FN)\n",
    "    spe = TN / (TN + FP)\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Train Epoch {epoch+1}/{num_epochs}, Acc: {acc:.4f}, Sen: {sen:.4f}, Spe: {spe:.4f}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    # 测试阶段\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    total_samples = 0\n",
    "    last_metric = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data,target = data.cuda(),target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total_samples += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        TP += ((predicted == 1) & (target == 1)).sum().item()\n",
    "        FN += ((predicted == 0) & (target == 1)).sum().item()\n",
    "        TN += ((predicted == 0) & (target == 0)).sum().item()\n",
    "        FP += ((predicted == 1) & (target == 0)).sum().item()\n",
    "\n",
    "    acc = correct / total_samples\n",
    "    sen = TP / (TP + FN)\n",
    "    spe = TN / (TN + FP)\n",
    "    score = sen*spe\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    print(f\"Test Epoch {epoch+1}/{num_epochs}, Acc: {acc:.4f}, Sen: {sen:.4f}, Spe: {spe:.4f}, Loss: {loss:.4f}\")\n",
    "    return model, score, sen, spe, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # 设置训练参数\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# 创建模型实例\n",
    "lenet = LeNet()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(lenet.parameters(), lr=learning_rate)\n",
    "\n",
    "lenet.to(device)\n",
    "\n",
    "best_model = None\n",
    "b_score = 0\n",
    "b_acc = 0\n",
    "b_sen = 0\n",
    "b_spe = 0\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    trained_model, score, sen, spe, acc = train(lenet, train_dataloader, test_dataloader, criterion, optimizer)\n",
    "    if score > b_score:\n",
    "        best_model = copy.deepcopy(trained_model)\n",
    "        b_score = score\n",
    "        b_acc = acc\n",
    "        b_sen = sen\n",
    "        b_spe = spe\n",
    "print(f\"Final metrics , Score: {b_score:.4f}, Acc: {b_acc:.4f}, Sen: {b_sen:.4f}, Spe: {b_spe:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存model为onnx格式\n",
    "# Prepare input tensor\n",
    "input_tensor = torch.randn(1, 1, 44, 44)\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Move model to the device\n",
    "best_model.to(device)\n",
    "\n",
    "directory = 'cnn'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "# Export models as ONNX files\n",
    "torch.onnx.export(best_model, input_tensor, \"cnn/lenet5.onnx\", opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = best_model(x_test.to(device))\n",
    "    ypred = torch.argmax(outputs.cpu(), dim=1)\n",
    "    TP = ((ypred == 1) & (y_test == 1)).sum()\n",
    "    FN = ((ypred == 0) & (y_test == 1)).sum()\n",
    "    TN = ((ypred == 0) & (y_test == 0)).sum()\n",
    "    FP = ((ypred == 1) & (y_test == 0)).sum()\n",
    "    sen = TP / (TP + FN)\n",
    "    spe = TN / (TN + FP)\n",
    "    print(sen,spe)\n",
    "    print(TP,FN,TN,FP)\n",
    "    print(ypred.sum(),y_test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate model\n",
    "from sklearn.metrics import classification_report,accuracy_score,roc_curve\n",
    "from sklearn.metrics import confusion_matrix,auc,RocCurveDisplay,plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "target_names = ['non-seizure', 'seizure']\n",
    "print(classification_report(y_test, ypred, target_names=target_names))\n",
    "confusion = confusion_matrix(y_test,ypred)\n",
    "ax = sns.heatmap(confusion, annot=True, fmt='g', cmap='Blues')\n",
    "ax.set_title('Confusion Matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['non-seizure', 'seizure'])\n",
    "ax.yaxis.set_ticklabels(['non-seizure', 'seizure'])\n",
    "\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "Acc=(TP+TN)/float(TP+TN+FP+FN)\n",
    "Sen=TP / float(TP+FN)\n",
    "Spe=TN / float(TN+FP)\n",
    "print('acc', Acc, 'sen',Sen,'spe',Spe)\n",
    "plt.savefig('cnn/matrix.png', dpi=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "dl_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
